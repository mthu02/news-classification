{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another metric with the same name already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-40869d1afbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtextblob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_layer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/mixed_precision/loss_scale_optimizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmart_cond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_loss_scale_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/optimizers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Imports needed for deserialization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madadelta\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0madadelta_legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madagrad\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0madagrad_legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madam\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0madam_legacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/optimizers/legacy/adadelta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Legacy Adadelta optimizer implementation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madadelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adadelta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# isort: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;34m\"/tensorflow/api/keras/optimizers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras optimizer usage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"method\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, description, *labels)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \"\"\"\n\u001b[1;32m    352\u001b[0m     super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,\n\u001b[0;32m--> 353\u001b[0;31m                                     len(labels), name, description, *labels)\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[1;32m    125\u001b[0m           self._metric_name, len(self._metric_methods)))\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."
     ]
    }
   ],
   "source": [
    "import py_vncorenlp\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from keras.layers import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "# Automatically download VnCoreNLP components from the original repository\n",
    "# and save them in some local machine folder\n",
    "py_vncorenlp.download_model(save_dir='/home/tlukay/thuattoanthongminh/source/vncorenlp')\n",
    "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/home/tlukay/thuattoanthongminh/source/vncorenlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader(object):\n",
    "    def __init__(self, filePath, encoder = None):\n",
    "        self.filePath = filePath\n",
    "        self.encoder = encoder if encoder != None else 'utf-16le'\n",
    "\n",
    "    def read_stopwords(self):\n",
    "        with open(self.filePath, 'r') as f:\n",
    "            stopwords = set([w.strip().replace(' ', '_') for w in f.readlines()])\n",
    "        return stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import re\n",
    "class NLP(object):\n",
    "    def __init__(self, text = None):\n",
    "        self.text = text\n",
    "        self.__set_stopwords()\n",
    "\n",
    "    def __set_stopwords(self):\n",
    "        self.stopwords = FileReader(settings.STOP_WORDS).read_stopwords()\n",
    "\n",
    "    def segmentation(self):\n",
    "        return rdrsegmenter.word_segment(self.text)\n",
    "\n",
    "    def split_words(self):\n",
    "        text = self.segmentation()\n",
    "        text = ' '.join(text)\n",
    "        try:\n",
    "            return [x.strip(settings.SPECIAL_CHARACTER).lower() for x in text.split()]\n",
    "        except TypeError:\n",
    "            return []\n",
    "\n",
    "    def standardize_data(self):\n",
    "        self.text = self.text.replace('\\n',' ').lower().strip()\n",
    "        self.text = re.sub(r\"[\\,\\?]+$-()!*=._\", \"\", self.text)\n",
    "        self.text = self.text.replace(\",\", \" \") \\\n",
    "            .replace(\";\", \" \").replace(\"“\", \" \") \\\n",
    "            .replace(\":\", \" \").replace(\"”\", \" \") \\\n",
    "            .replace('\"', \" \").replace(\"'\", \" \") \\\n",
    "            .replace(\"!\", \" \").replace(\"?\", \" \") \\\n",
    "            .replace(\"-\", \" \").replace(\"*\", \" \")\\\n",
    "            .replace(\"=\", \" \").replace(\"(\", \" \")\\\n",
    "            .replace(\")\", \" \").replace(\"_\", \" \").replace(\".\", \" \")\n",
    "        self.text = self.text.strip().lower()\n",
    "        return self.text      \n",
    "\n",
    "    def get_words_feature(self):\n",
    "        split_words = self.standardize_data()\n",
    "        split_words = self.split_words()\n",
    "        \n",
    "        return [word for word in split_words if word not in self.stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 983/5219 [00:10<00:36, 117.31it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3869b079a182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/tlukay/thuattoanthongminh/source/data/10_cate/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-3869b079a182>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_words_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d674f6f5ba2e>\u001b[0m in \u001b[0;36mget_words_feature\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_words_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msplit_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msplit_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_words\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d674f6f5ba2e>\u001b[0m in \u001b[0;36msplit_words\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d674f6f5ba2e>\u001b[0m in \u001b[0;36msegmentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrdrsegmenter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_segment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py_vncorenlp/vncorenlp.py\u001b[0m in \u001b[0;36mword_segment\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjavaclass_String\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjavaclass_Annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mlist_segmented_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mlist_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Data')\n",
    "\n",
    "# Load data from dataset folder\n",
    "def get_data(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    dirs = os.listdir(folder_path)\n",
    "    for path in dirs:\n",
    "        file_paths = os.listdir(os.path.join(folder_path, path))\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with open(os.path.join(folder_path, path, file_path), 'r', encoding=\"utf-16\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                lines = NLP(text = lines).get_words_feature()\n",
    "                lines = ' '.join(lines)\n",
    "                X.append(lines)\n",
    "                y.append(path)\n",
    "                \n",
    "    return X, y\n",
    "\n",
    "train_path = os.path.join(dir_path, '/home/tlukay/thuattoanthongminh/source/data/10_cate/train')\n",
    "X_data, y_data = get_data(train_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X_data, open('/home/tlukay/thuattoanthongminh/source/data/X_data.pkl', 'wb'))\n",
    "pickle.dump(y_data, open('/home/tlukay/thuattoanthongminh/source/data/y_data.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7567/7567 [00:55<00:00, 137.35it/s]\n",
      "100%|██████████| 4560/4560 [00:30<00:00, 149.28it/s]\n",
      "100%|██████████| 6716/6716 [00:41<00:00, 162.05it/s]\n",
      "100%|██████████| 5417/5417 [00:43<00:00, 123.68it/s]\n",
      "100%|██████████| 2096/2096 [00:16<00:00, 124.13it/s]\n",
      "100%|██████████| 2036/2036 [00:21<00:00, 93.25it/s] \n",
      "100%|██████████| 6667/6667 [01:10<00:00, 94.03it/s] \n",
      "100%|██████████| 6250/6250 [00:50<00:00, 122.84it/s]\n",
      "100%|██████████| 5276/5276 [00:42<00:00, 124.72it/s]\n",
      "100%|██████████| 3788/3788 [00:29<00:00, 127.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(dir_path, '/home/tlukay/thuattoanthongminh/source/data/10_cate/test')\n",
    "X_test, y_test = get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_test, open('/home/tlukay/thuattoanthongminh/source/data/X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open('/home/tlukay/thuattoanthongminh/source/data/y_test.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2> Feature Engineering </h2>\n",
    "\n",
    "In this step, raw text data will be transformed into eature vectors and new features will be created using the existing dataset. We will implement some idea as follows:\n",
    "\n",
    "1. Count Vectors as features\n",
    "2. TF-IDF Vectors as features\n",
    "\n",
    "    2.1 Word level\n",
    "\n",
    "    2.2. N-Gram level\n",
    "\n",
    "    2.3. Character level\n",
    "    \n",
    "3. Word Embeddings as features\n",
    "4. Text / NLP based features\n",
    "5. Topic Models as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_data = pickle.load(open('/home/tlukay/thuattoanthongminh/source/data/X_data.pkl', 'rb'))\n",
    "y_data = pickle.load(open('/home/tlukay/thuattoanthongminh/source/data/y_data.pkl', 'rb'))\n",
    "\n",
    "X_test = pickle.load(open('/home/tlukay/thuattoanthongminh/source/data/X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open('/home/tlukay/thuattoanthongminh/source/data/y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Count Vectors as features</h3>\n",
    "\n",
    "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X_data)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "X_data_count = count_vect.transform(X_data)\n",
    "X_test_count = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>TF-IDF Vectors</h3>\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "TF-IDF Vectors can be generated at different levels of input tokens (words, characters, n-grams)\n",
    "\n",
    "a. Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n",
    "\n",
    "b. N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
    "\n",
    "c. Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level - we choose max number of words equal to 30000 except all words (100k+ words)\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=30000)\n",
    "tfidf_vect.fit(X_data) # learn vocabulary and idf from training set\n",
    "X_data_tfidf =  tfidf_vect.transform(X_data)\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_kiều',\n",
       " '_mai_công',\n",
       " '_sỹ',\n",
       " 'a_dua',\n",
       " 'a_gia',\n",
       " 'a_giao',\n",
       " 'a_vương',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aac',\n",
       " 'aachen',\n",
       " 'aaron',\n",
       " 'aas',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abashidze',\n",
       " 'abba',\n",
       " 'abbas',\n",
       " 'abbey',\n",
       " 'abbiati',\n",
       " 'abbondanzieri',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdel',\n",
       " 'abdelrahim',\n",
       " 'abdoulaye',\n",
       " 'abdul',\n",
       " 'abdulaziz',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abeyie',\n",
       " 'abf',\n",
       " 'abidjan',\n",
       " 'abkhazia',\n",
       " 'able2extract',\n",
       " 'abn',\n",
       " 'about',\n",
       " 'abqaiq',\n",
       " 'abraham',\n",
       " 'abramoff',\n",
       " 'abramovich',\n",
       " 'abs',\n",
       " 'abtc',\n",
       " 'abu',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acasiete',\n",
       " 'acb',\n",
       " 'acbs',\n",
       " 'accc',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'account',\n",
       " 'accumbens',\n",
       " 'ace',\n",
       " 'aceh',\n",
       " 'acer',\n",
       " 'acetaminophen',\n",
       " 'achilefu',\n",
       " 'achilles',\n",
       " 'acid',\n",
       " 'acid_amin',\n",
       " 'acid_béo',\n",
       " 'acid_folic',\n",
       " 'acl',\n",
       " 'acm',\n",
       " 'acoo',\n",
       " 'acpe',\n",
       " 'acrobat',\n",
       " 'acronis',\n",
       " 'acropolis',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activex',\n",
       " 'acuff',\n",
       " 'acyclovir',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adan',\n",
       " 'adani',\n",
       " 'adapter',\n",
       " 'adb',\n",
       " 'add',\n",
       " 'address',\n",
       " 'addvote',\n",
       " 'adebayor',\n",
       " 'adel',\n",
       " 'adelaide',\n",
       " 'adelman',\n",
       " 'aden',\n",
       " 'adeno',\n",
       " 'adeportivo',\n",
       " 'adidas',\n",
       " 'adler',\n",
       " 'admin',\n",
       " 'adn',\n",
       " 'adnan',\n",
       " 'adobe',\n",
       " 'adodb',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adriano',\n",
       " 'adsl',\n",
       " 'adu',\n",
       " 'adulyadej',\n",
       " 'aduôm',\n",
       " 'advanced',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'advocaat',\n",
       " 'adware',\n",
       " 'adzharia',\n",
       " 'ae',\n",
       " 'aegypti',\n",
       " 'aek',\n",
       " 'aerobic',\n",
       " 'aerospace',\n",
       " 'af',\n",
       " 'afa',\n",
       " 'afc',\n",
       " 'afd',\n",
       " 'aff',\n",
       " 'affleck',\n",
       " 'afghanistan',\n",
       " 'afp',\n",
       " 'afta',\n",
       " 'after',\n",
       " 'ag',\n",
       " 'ag2r',\n",
       " 'again',\n",
       " 'agamemnon',\n",
       " 'agassi',\n",
       " 'age',\n",
       " 'agf',\n",
       " 'agger',\n",
       " 'agifish',\n",
       " 'agnelli',\n",
       " 'agobot',\n",
       " 'agostino',\n",
       " 'agra',\n",
       " 'agresto',\n",
       " 'agribank',\n",
       " 'agricole',\n",
       " 'ags',\n",
       " 'agtek',\n",
       " 'agu',\n",
       " 'aguilar',\n",
       " 'aguilera',\n",
       " 'agus',\n",
       " 'agustin',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahern',\n",
       " 'ahmad',\n",
       " 'ahmadinejad',\n",
       " 'ahmed',\n",
       " 'ahn',\n",
       " 'ahv',\n",
       " 'ai_cập',\n",
       " 'ai_lại',\n",
       " 'ai_ngờ',\n",
       " 'ai_oán',\n",
       " 'ai_đời',\n",
       " 'aia',\n",
       " 'aiboy',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aids',\n",
       " 'aig',\n",
       " 'aiko',\n",
       " 'ailen',\n",
       " 'ailton',\n",
       " 'aim',\n",
       " 'aimar',\n",
       " 'aime',\n",
       " 'ain',\n",
       " 'aio',\n",
       " 'air',\n",
       " 'airbus',\n",
       " 'aires',\n",
       " 'airlines',\n",
       " 'airways',\n",
       " 'ait',\n",
       " 'aitor',\n",
       " 'aiyegbeni',\n",
       " 'aj',\n",
       " 'ajax',\n",
       " 'ajc',\n",
       " 'ajinomoto',\n",
       " 'ak',\n",
       " 'akayev',\n",
       " 'akbar',\n",
       " 'akhtar',\n",
       " 'akinfeev',\n",
       " 'akira',\n",
       " 'akishino',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alain',\n",
       " 'alam',\n",
       " 'alamsyah',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'alaves',\n",
       " 'alawi',\n",
       " 'alba',\n",
       " 'albacete',\n",
       " 'albania',\n",
       " 'albelda',\n",
       " 'albena',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertini',\n",
       " 'alberto',\n",
       " 'albion',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'albumin',\n",
       " 'alcatel',\n",
       " 'alcomto',\n",
       " 'aldo',\n",
       " 'aldonin',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'alegre',\n",
       " 'alejandro',\n",
       " 'aleksander',\n",
       " 'aleksandr',\n",
       " 'aleksandrs',\n",
       " 'alenichev',\n",
       " 'alert',\n",
       " 'alessandro',\n",
       " 'alessio',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alexandria',\n",
       " 'alexei',\n",
       " 'alexey',\n",
       " 'alexis',\n",
       " 'alezboo',\n",
       " 'alfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algeria',\n",
       " 'ali',\n",
       " 'aliadiere',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alienware',\n",
       " 'alive',\n",
       " 'aliénor',\n",
       " 'alkmaar',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allardyce',\n",
       " 'allawi',\n",
       " 'allback',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'allianz',\n",
       " 'almeida',\n",
       " 'almeyda',\n",
       " 'almunia',\n",
       " 'alofun',\n",
       " 'alonso',\n",
       " 'alpe',\n",
       " 'alpha',\n",
       " 'alphanam',\n",
       " 'alphonse',\n",
       " 'alpi',\n",
       " 'alps',\n",
       " 'alt',\n",
       " 'altavista',\n",
       " 'alternative',\n",
       " 'altintop',\n",
       " 'altis',\n",
       " 'alvarez',\n",
       " 'alvaro',\n",
       " 'alves',\n",
       " 'alvin',\n",
       " 'alwaleed',\n",
       " 'alzheimer',\n",
       " 'am',\n",
       " 'am_hiểu',\n",
       " 'am_tường',\n",
       " 'ama',\n",
       " 'amador',\n",
       " 'aman',\n",
       " 'amanda',\n",
       " 'amantadine',\n",
       " 'amaobi',\n",
       " 'amara',\n",
       " 'amarilla',\n",
       " 'amaseco',\n",
       " 'amath',\n",
       " 'amazon',\n",
       " 'ambrose',\n",
       " 'ambrosini',\n",
       " 'ambrosio',\n",
       " 'amcham',\n",
       " 'amd',\n",
       " 'amedeo',\n",
       " 'amelia',\n",
       " 'amelie',\n",
       " 'ameobi',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amie',\n",
       " 'amin',\n",
       " 'amino',\n",
       " 'amir',\n",
       " 'amiro',\n",
       " 'amiăng',\n",
       " 'amiđan',\n",
       " 'amjad',\n",
       " 'amma',\n",
       " 'amman',\n",
       " 'ammar',\n",
       " 'amoniac',\n",
       " 'amore',\n",
       " 'amoro',\n",
       " 'amoroso',\n",
       " 'amoruso',\n",
       " 'amour',\n",
       " 'amoxicillin',\n",
       " 'amp',\n",
       " 'ampad',\n",
       " 'ampli',\n",
       " 'amposted',\n",
       " 'amr',\n",
       " 'amri',\n",
       " 'amsterdam',\n",
       " 'amstrong',\n",
       " 'amsubject',\n",
       " 'amy',\n",
       " 'amíp',\n",
       " 'an',\n",
       " 'an_bài',\n",
       " 'an_cư',\n",
       " 'an_cư_lạc_nghiệp',\n",
       " 'an_dương',\n",
       " 'an_dương_vương',\n",
       " 'an_giang',\n",
       " 'an_hưởng',\n",
       " 'an_khang',\n",
       " 'an_khê',\n",
       " 'an_lành',\n",
       " 'an_lão',\n",
       " 'an_lạc',\n",
       " 'an_nghỉ',\n",
       " 'an_nhàn',\n",
       " 'an_nhơn',\n",
       " 'an_ninh',\n",
       " 'an_phú',\n",
       " 'an_phú_đông',\n",
       " 'an_phận',\n",
       " 'an_sinh',\n",
       " 'an_thai',\n",
       " 'an_thần',\n",
       " 'an_toàn',\n",
       " 'an_toàn_lao_động',\n",
       " 'an_táng',\n",
       " 'an_tâm',\n",
       " 'an_ủi',\n",
       " 'ana',\n",
       " 'analog',\n",
       " 'analytics',\n",
       " 'anara',\n",
       " 'anastasia',\n",
       " 'anatoly',\n",
       " 'anbar',\n",
       " 'ancelotti',\n",
       " 'ancic',\n",
       " 'ancona',\n",
       " 'and',\n",
       " 'andaman',\n",
       " 'anderlecht',\n",
       " 'anders',\n",
       " 'andersen',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'anderton',\n",
       " 'andes',\n",
       " 'andorra',\n",
       " 'andrade',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andreev',\n",
       " 'andrei',\n",
       " 'andreina',\n",
       " 'andrejs',\n",
       " 'andres',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'andrey',\n",
       " 'andriy',\n",
       " 'androgen',\n",
       " 'andré',\n",
       " 'andy',\n",
       " 'anelka',\n",
       " 'anfield',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angelos',\n",
       " 'angels',\n",
       " 'angkor',\n",
       " 'anglia',\n",
       " 'angola',\n",
       " 'angresto',\n",
       " 'angulo',\n",
       " 'anh_chàng',\n",
       " 'anh_chị',\n",
       " 'anh_chị_em',\n",
       " 'anh_cả',\n",
       " 'anh_dũng',\n",
       " 'anh_em',\n",
       " 'anh_hoa',\n",
       " 'anh_hào',\n",
       " 'anh_hùng',\n",
       " 'anh_hùng_ca',\n",
       " 'anh_kiệt',\n",
       " 'anh_linh',\n",
       " 'anh_minh',\n",
       " 'anh_nuôi',\n",
       " 'anh_quân',\n",
       " 'anh_sơn',\n",
       " 'anh_thư',\n",
       " 'anh_trai',\n",
       " 'anh_tuấn',\n",
       " 'anh_tài',\n",
       " 'anh_túc',\n",
       " 'anh_vũ',\n",
       " 'anh_ách',\n",
       " 'anh_ánh',\n",
       " 'anh_đào',\n",
       " 'anhto',\n",
       " 'anigo',\n",
       " 'anisensel',\n",
       " 'aniston',\n",
       " 'ankara',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annan',\n",
       " 'anne',\n",
       " 'anolyte',\n",
       " 'another',\n",
       " 'anousone',\n",
       " 'ansar',\n",
       " 'antar',\n",
       " 'anten',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antigua',\n",
       " 'antioquia',\n",
       " 'antivirus',\n",
       " 'anto',\n",
       " 'antoine',\n",
       " 'antoinette',\n",
       " 'anton',\n",
       " 'antonio',\n",
       " 'antonioli',\n",
       " 'antonis',\n",
       " 'antony',\n",
       " 'antt',\n",
       " 'anwar',\n",
       " 'anz',\n",
       " 'anđt',\n",
       " 'ao',\n",
       " 'ao_hồ',\n",
       " 'ao_ước',\n",
       " 'aol',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apartheid',\n",
       " 'apd',\n",
       " 'apec',\n",
       " 'aperture',\n",
       " 'aphrodite',\n",
       " 'api',\n",
       " 'apollo',\n",
       " 'appf',\n",
       " 'appiah',\n",
       " 'apple',\n",
       " 'applet',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'april',\n",
       " 'aps',\n",
       " 'apsara',\n",
       " 'aptech',\n",
       " 'apu',\n",
       " 'apwg',\n",
       " 'aqa',\n",
       " 'aqsa',\n",
       " 'aquilani',\n",
       " 'aquino',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'araban',\n",
       " 'arabia',\n",
       " 'arabiya',\n",
       " 'arafat',\n",
       " 'aragones',\n",
       " 'arakawa',\n",
       " 'aral',\n",
       " 'aranda',\n",
       " 'arango',\n",
       " 'aranzubia',\n",
       " 'araujo',\n",
       " 'arazi',\n",
       " 'archaeopteryx',\n",
       " 'architecture',\n",
       " 'archiver',\n",
       " 'archives',\n",
       " 'are',\n",
       " 'arellano',\n",
       " 'arem',\n",
       " 'arena',\n",
       " 'argentina',\n",
       " 'argilli',\n",
       " 'arginine',\n",
       " 'argon',\n",
       " 'ari',\n",
       " 'ariane',\n",
       " 'arie',\n",
       " 'ariel',\n",
       " 'aristide',\n",
       " 'arizona',\n",
       " 'arjen',\n",
       " 'arjhan',\n",
       " 'arkansas',\n",
       " 'armand',\n",
       " 'armando',\n",
       " 'armani',\n",
       " 'armavia',\n",
       " 'armenia',\n",
       " 'arminia',\n",
       " 'armitage',\n",
       " 'armstrong',\n",
       " 'arn',\n",
       " 'arne',\n",
       " 'arnold',\n",
       " 'arosa',\n",
       " 'array',\n",
       " 'arrese',\n",
       " 'arrigo',\n",
       " 'arroyo',\n",
       " 'arruabarrena',\n",
       " 'arsen',\n",
       " 'arsenal',\n",
       " 'arsene',\n",
       " 'arshavin',\n",
       " 'art',\n",
       " 'artemisinin',\n",
       " 'arteta',\n",
       " 'arthur',\n",
       " 'articleid',\n",
       " 'artmedia',\n",
       " 'arts',\n",
       " 'arturo',\n",
       " 'arv',\n",
       " 'arập',\n",
       " 'as',\n",
       " 'asa',\n",
       " 'asada',\n",
       " 'asahara',\n",
       " 'asahi',\n",
       " 'asamoah',\n",
       " 'ascender',\n",
       " 'ascii',\n",
       " 'ascoli',\n",
       " 'asda',\n",
       " 'asean',\n",
       " 'asefi',\n",
       " 'asem',\n",
       " 'asep',\n",
       " 'asha',\n",
       " 'ashampoo',\n",
       " 'ashcroft',\n",
       " 'ashdown',\n",
       " 'ashfaq',\n",
       " 'ashima',\n",
       " 'ashlee',\n",
       " 'ashley',\n",
       " 'ashraf',\n",
       " 'ashton',\n",
       " 'asia',\n",
       " 'asiad',\n",
       " 'asian',\n",
       " 'asianux',\n",
       " 'asic',\n",
       " 'asimo',\n",
       " 'asin',\n",
       " 'ask',\n",
       " 'aslan',\n",
       " 'aslem',\n",
       " 'asn',\n",
       " 'aso',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'asperger',\n",
       " 'aspergillus',\n",
       " 'aspire',\n",
       " 'aspirin',\n",
       " 'aspirine',\n",
       " 'aspx',\n",
       " 'assad',\n",
       " 'assam',\n",
       " 'assis',\n",
       " 'associates',\n",
       " 'astafjevs',\n",
       " 'astaman',\n",
       " 'aston',\n",
       " 'asus',\n",
       " 'at',\n",
       " 'ata',\n",
       " 'atak',\n",
       " 'atal',\n",
       " 'atalanta',\n",
       " 'atb',\n",
       " 'atc',\n",
       " 'atf',\n",
       " 'atgt',\n",
       " 'athen',\n",
       " 'athens',\n",
       " 'athletic',\n",
       " 'athlon',\n",
       " 'ati',\n",
       " 'atisô',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atlantis',\n",
       " 'atlas',\n",
       " 'atletico',\n",
       " 'atm',\n",
       " 'atomic',\n",
       " 'atp',\n",
       " 'atr',\n",
       " 'att',\n",
       " 'attack',\n",
       " 'atthipol',\n",
       " 'attila',\n",
       " 'attogiây',\n",
       " 'atvstp',\n",
       " 'au',\n",
       " 'auc',\n",
       " 'auckland',\n",
       " 'aud',\n",
       " 'audio',\n",
       " 'audrey',\n",
       " 'augenthaler',\n",
       " 'august',\n",
       " 'augustus',\n",
       " 'aulas',\n",
       " 'aum',\n",
       " 'aung',\n",
       " 'aura',\n",
       " 'aurelio',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'auto',\n",
       " 'autocad',\n",
       " 'autodesk',\n",
       " 'automatic',\n",
       " 'automotive',\n",
       " 'autopetro',\n",
       " 'auxerre',\n",
       " 'av',\n",
       " 'aventis',\n",
       " 'avery',\n",
       " 'avg',\n",
       " 'avi',\n",
       " 'aviv',\n",
       " 'avon',\n",
       " 'avramovic',\n",
       " 'avril',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'axa',\n",
       " 'axel',\n",
       " 'axit',\n",
       " 'axit_amin',\n",
       " 'axít',\n",
       " 'ay',\n",
       " 'ayad',\n",
       " 'ayala',\n",
       " 'ayman',\n",
       " 'ayre',\n",
       " 'ayrton',\n",
       " 'ayub',\n",
       " 'az',\n",
       " 'azerbaijan',\n",
       " 'azevedo',\n",
       " 'azithromycin',\n",
       " 'aziz',\n",
       " 'aztec',\n",
       " 'aztecs',\n",
       " 'azul',\n",
       " 'azzam',\n",
       " 'aê',\n",
       " 'ba',\n",
       " 'ba_bể',\n",
       " 'ba_bị',\n",
       " 'ba_gác',\n",
       " 'ba_hoa',\n",
       " 'ba_kích',\n",
       " 'ba_lan',\n",
       " 'ba_lô',\n",
       " 'ba_má',\n",
       " 'ba_mươi',\n",
       " 'ba_mẹ',\n",
       " 'ba_phải',\n",
       " 'ba_rọi',\n",
       " 'ba_sa',\n",
       " 'ba_son',\n",
       " 'ba_tháng_hai',\n",
       " 'ba_tri',\n",
       " 'ba_tơ',\n",
       " 'ba_vì',\n",
       " 'ba_đình',\n",
       " 'baath',\n",
       " 'babayaro',\n",
       " 'babel',\n",
       " 'babic',\n",
       " 'baby',\n",
       " 'babylon',\n",
       " 'bac',\n",
       " 'bach',\n",
       " 'bachelet',\n",
       " 'bachri',\n",
       " 'back',\n",
       " 'backdoor',\n",
       " 'backstedt',\n",
       " 'backstreet',\n",
       " 'backup',\n",
       " 'bacolod',\n",
       " 'bad',\n",
       " 'badawi',\n",
       " 'baden',\n",
       " 'bae',\n",
       " 'baez',\n",
       " 'baggio',\n",
       " 'baghdad',\n",
       " 'baghdatis',\n",
       " 'bagle',\n",
       " 'bahnar',\n",
       " 'bahrain',\n",
       " 'baht',\n",
       " 'bai',\n",
       " 'baia',\n",
       " 'baiano',\n",
       " 'baidu',\n",
       " 'baihakki',\n",
       " 'baikal',\n",
       " 'bakar',\n",
       " 'baker',\n",
       " 'bakery',\n",
       " 'bakiev',\n",
       " 'baku',\n",
       " 'baldini',\n",
       " 'baldwin',\n",
       " 'balears',\n",
       " 'bali',\n",
       " 'balkan',\n",
       " 'balkans',\n",
       " 'ball',\n",
       " 'ballack',\n",
       " 'ballad',\n",
       " 'balladur',\n",
       " 'ballast',\n",
       " 'ballesta',\n",
       " 'ballet',\n",
       " 'balli',\n",
       " 'ballmer',\n",
       " 'baltic',\n",
       " 'baltimore',\n",
       " 'balzaretti',\n",
       " 'balô',\n",
       " 'bam',\n",
       " 'bambang',\n",
       " 'ban',\n",
       " 'ban_bí_thư',\n",
       " 'ban_bố',\n",
       " 'ban_chấp_hành',\n",
       " 'ban_công',\n",
       " 'ban_giám_hiệu',\n",
       " 'ban_hành',\n",
       " 'ban_mai',\n",
       " 'ban_ngành',\n",
       " 'ban_ngày',\n",
       " 'ban_phát',\n",
       " 'ban_tặng',\n",
       " 'ban_đêm',\n",
       " 'ban_đầu',\n",
       " 'ban_ơn',\n",
       " 'bana',\n",
       " 'band',\n",
       " 'banda',\n",
       " 'bandar',\n",
       " 'bandung',\n",
       " 'bang',\n",
       " 'bang_giao',\n",
       " 'bangalore',\n",
       " 'bangkok',\n",
       " 'bangladesh',\n",
       " 'banh',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'banknet',\n",
       " 'banks',\n",
       " 'banluesak',\n",
       " 'banner',\n",
       " 'bao',\n",
       " 'bao_biện',\n",
       " 'bao_bì',\n",
       " 'bao_bọc',\n",
       " 'bao_cao_su',\n",
       " 'bao_che',\n",
       " 'bao_cấp',\n",
       " 'bao_dung',\n",
       " 'bao_gói',\n",
       " 'bao_gồm',\n",
       " 'bao_hàm',\n",
       " 'bao_la',\n",
       " 'bao_phủ',\n",
       " 'bao_quát',\n",
       " 'bao_sân',\n",
       " 'bao_tay',\n",
       " 'bao_tiêu',\n",
       " 'bao_trùm',\n",
       " 'bao_tải',\n",
       " 'bao_tử',\n",
       " 'bao_vây',\n",
       " 'bao_xa',\n",
       " 'baptista',\n",
       " 'baquba',\n",
       " 'bar',\n",
       " 'baraja',\n",
       " 'barbara',\n",
       " 'barbie',\n",
       " 'barbiero',\n",
       " 'barbosa',\n",
       " 'barca',\n",
       " 'barcelona',\n",
       " 'barclays',\n",
       " 'bardot',\n",
       " 'barghouti',\n",
       " 'bari',\n",
       " 'baric',\n",
       " 'barie',\n",
       " 'barleygrass',\n",
       " 'barlow',\n",
       " 'barnes',\n",
       " 'barney',\n",
       " 'barnier',\n",
       " 'barone',\n",
       " 'baros',\n",
       " 'barr',\n",
       " 'barracuda',\n",
       " 'barreto',\n",
       " 'barrett',\n",
       " 'barrichello',\n",
       " 'barrie',\n",
       " 'barroso',\n",
       " 'barrot',\n",
       " 'barry',\n",
       " 'barrymore',\n",
       " 'bart',\n",
       " 'barthez',\n",
       " 'bartlett',\n",
       " 'barton',\n",
       " 'barwick',\n",
       " 'bas',\n",
       " 'basa',\n",
       " 'basayev',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basedow',\n",
       " 'basel',\n",
       " 'bashir',\n",
       " 'basic',\n",
       " 'basil',\n",
       " 'basinas',\n",
       " 'basque',\n",
       " 'basra',\n",
       " 'bass',\n",
       " 'basso',\n",
       " 'basten',\n",
       " 'bastian',\n",
       " 'bat',\n",
       " 'bates',\n",
       " 'bath',\n",
       " 'baumann',\n",
       " 'baumgardner',\n",
       " 'baumgartner',\n",
       " 'bautista',\n",
       " 'bavaria',\n",
       " 'bavet',\n",
       " 'bay_bướm',\n",
       " 'bay_bổng',\n",
       " 'bay_hơi',\n",
       " 'bay_lượn',\n",
       " 'bay_nhảy',\n",
       " 'bayati',\n",
       " 'bayer',\n",
       " 'bayern',\n",
       " 'bazan',\n",
       " 'bazzani',\n",
       " 'bađm',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbt',\n",
       " 'bbàn',\n",
       " 'bc',\n",
       " 'bca',\n",
       " 'bcb',\n",
       " 'bcc',\n",
       " 'bch',\n",
       " 'bcht',\n",
       " 'bchtư',\n",
       " 'bci',\n",
       " 'bct',\n",
       " 'bcvt',\n",
       " 'bd',\n",
       " 'bdd',\n",
       " 'bdelloid',\n",
       " 'bdr',\n",
       " 'bdynamo',\n",
       " 'be',\n",
       " 'be_bé',\n",
       " 'be_bét',\n",
       " 'bea',\n",
       " 'beach',\n",
       " 'beagle',\n",
       " 'bean',\n",
       " 'beasley',\n",
       " 'beatles',\n",
       " 'beattie',\n",
       " 'beaujolais',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bec',\n",
       " 'becamex',\n",
       " 'becgiê',\n",
       " 'beck',\n",
       " 'beckenbauer',\n",
       " 'becker',\n",
       " 'beckham',\n",
       " 'becks',\n",
       " 'bee',\n",
       " 'been',\n",
       " 'beenhakker',\n",
       " 'beer',\n",
       " 'beethoven',\n",
       " 'bega',\n",
       " 'begin',\n",
       " 'behari',\n",
       " 'behr',\n",
       " 'beijing',\n",
       " 'beirut',\n",
       " 'bejan',\n",
       " 'belanov',\n",
       " 'belarus',\n",
       " 'belem',\n",
       " 'belfast',\n",
       " 'belgrade',\n",
       " 'belka',\n",
       " 'bell',\n",
       " 'bellamy',\n",
       " 'belletti',\n",
       " 'bellion',\n",
       " 'bells',\n",
       " 'bellucci',\n",
       " 'bellview',\n",
       " 'belozoglu',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level - we choose max number of words equal to 30000 except all words (100k+ words)\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', max_features=30000, ngram_range=(2, 3))\n",
    "tfidf_vect_ngram.fit(X_data)\n",
    "X_data_tfidf_ngram =  tfidf_vect_ngram.transform(X_data)\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdul aziz',\n",
       " 'abu ghraib',\n",
       " 'abu musab',\n",
       " 'abu musab al',\n",
       " 'ac milan',\n",
       " 'ac milan as',\n",
       " 'ac milan inter',\n",
       " 'ac milan juventus',\n",
       " 'ac milan thắng',\n",
       " 'ac milan thủ_môn',\n",
       " 'ac milan đấu',\n",
       " 'acb bình',\n",
       " 'acb bình dương',\n",
       " 'acb hà_nội',\n",
       " 'acb slna',\n",
       " 'acb slna bình',\n",
       " 'acid uric',\n",
       " 'acyclovir mg',\n",
       " 'adrian mutu',\n",
       " 'adriano inter',\n",
       " 'adriano inter milan',\n",
       " 'afc champions',\n",
       " 'afc champions league',\n",
       " 'agribank cup',\n",
       " 'agu casmir',\n",
       " 'ahmed korei',\n",
       " 'ai_cập cổ',\n",
       " 'ai_cập cổ_đại',\n",
       " 'air france',\n",
       " 'ajax amsterdam',\n",
       " 'ajax tel',\n",
       " 'ajax tel aviv',\n",
       " 'al aqsa',\n",
       " 'al ittihad',\n",
       " 'al jazeera',\n",
       " 'al jazeera phát',\n",
       " 'al qaeda',\n",
       " 'al qeada',\n",
       " 'al salaam',\n",
       " 'al sunna',\n",
       " 'al zarqawi',\n",
       " 'alam shah',\n",
       " 'alan curbishley',\n",
       " 'alan greenspan',\n",
       " 'alan shearer',\n",
       " 'alan shearer newcastle',\n",
       " 'alan smith',\n",
       " 'albert einstein',\n",
       " 'albert luque',\n",
       " 'alberto gilardino',\n",
       " 'alberto gilardino parma',\n",
       " 'album album',\n",
       " 'album ca_khúc',\n",
       " 'album ca_sĩ',\n",
       " 'album hát',\n",
       " 'album nhạc',\n",
       " 'album phát_hành',\n",
       " 'album ra_mắt',\n",
       " 'album vol',\n",
       " 'album đầu_tay',\n",
       " 'album ảnh',\n",
       " 'ale com',\n",
       " 'alessandro del',\n",
       " 'alessandro del piero',\n",
       " 'alessandro nesta',\n",
       " 'alex ferguson',\n",
       " 'alexander frei',\n",
       " 'alexei smertin',\n",
       " 'alfred riedl',\n",
       " 'ali karimi',\n",
       " 'allianz arena',\n",
       " 'alonso renault',\n",
       " 'am subject',\n",
       " 'am subject chi',\n",
       " 'am subject chia',\n",
       " 'am subject gui',\n",
       " 'am subject toi',\n",
       " 'amelie mauresmo',\n",
       " 'american airlines',\n",
       " 'american idol',\n",
       " 'amp cup',\n",
       " 'amp montenegro',\n",
       " 'amp nv',\n",
       " 'amp phát_triển',\n",
       " 'amp phát_triển nông_thôn',\n",
       " 'amp ptnt',\n",
       " 'amp tobago',\n",
       " 'amp xh',\n",
       " 'amp đt',\n",
       " 'an an',\n",
       " 'an bình',\n",
       " 'an bình tây',\n",
       " 'an chồng',\n",
       " 'an hoà',\n",
       " 'an khánh',\n",
       " 'an sương',\n",
       " 'an thuyên',\n",
       " 'an thái',\n",
       " 'an thới',\n",
       " 'an tp',\n",
       " 'an_ninh chính_trị',\n",
       " 'an_ninh iraq',\n",
       " 'an_ninh israel',\n",
       " 'an_ninh khu_vực',\n",
       " 'an_ninh kinh_tế',\n",
       " 'an_ninh mỹ',\n",
       " 'an_ninh nội_địa',\n",
       " 'an_ninh palestine',\n",
       " 'an_ninh quốc_gia',\n",
       " 'an_ninh quốc_phòng',\n",
       " 'an_ninh trật_tự',\n",
       " 'an_ninh tăng_cường',\n",
       " 'an_ninh văn_hoá',\n",
       " 'an_ninh điều_tra',\n",
       " 'an_ninh điều_tra công_an',\n",
       " 'an_ninh ảrập',\n",
       " 'an_ninh ảrập xêút',\n",
       " 'an_sinh xã_hội',\n",
       " 'an_toàn giao_thông',\n",
       " 'an_toàn giao_thông quốc_gia',\n",
       " 'an_toàn hiệu_quả',\n",
       " 'an_toàn thực_phẩm',\n",
       " 'an_toàn tuyệt_đối',\n",
       " 'an_toàn tàu',\n",
       " 'an_toàn tính_mạng',\n",
       " 'an_toàn vệ_sinh',\n",
       " 'an_toàn vệ_sinh thực_phẩm',\n",
       " 'an_toàn xã_hội',\n",
       " 'an_táng chủ_tịch',\n",
       " 'an_táng chủ_tịch arafat',\n",
       " 'an_táng tang_lễ',\n",
       " 'an_táng tang_lễ arafat',\n",
       " 'anastasia myskina',\n",
       " 'and the',\n",
       " 'anderlecht bảng',\n",
       " 'anderlecht bảng chelsea',\n",
       " 'andre agassi',\n",
       " 'andrea caracciolo',\n",
       " 'andrea caracciolo brescia',\n",
       " 'andrea pirlo',\n",
       " 'andreas kloden',\n",
       " 'andrew carnegie',\n",
       " 'andriy shevchenko',\n",
       " 'andriy shevchenko ac',\n",
       " 'andy cole',\n",
       " 'andy roddick',\n",
       " 'andy van',\n",
       " 'andy van der',\n",
       " 'angelina jolie',\n",
       " 'angelos haristeas',\n",
       " 'anh_chị_em ruột',\n",
       " 'anh_dũng dũng',\n",
       " 'anh_dũng dũng huế',\n",
       " 'anh_em ruột',\n",
       " 'anh_hùng lao_động',\n",
       " 'anh_hùng lực_lượng_vũ_trang',\n",
       " 'anna kournikova',\n",
       " 'ansar al',\n",
       " 'ansar al sunna',\n",
       " 'anti virus',\n",
       " 'antonio cassano',\n",
       " 'antonio reyes',\n",
       " 'antonis nikopolidis',\n",
       " 'ao cá',\n",
       " 'ao dai',\n",
       " 'april am',\n",
       " 'april am subject',\n",
       " 'april pm',\n",
       " 'april pm subject',\n",
       " 'arafat cairo',\n",
       " 'arafat cairo bác_sĩ',\n",
       " 'arafat giải_phẫu',\n",
       " 'arafat giải_phẫu tử_thi',\n",
       " 'arafat gái',\n",
       " 'arafat gái arafat',\n",
       " 'arafat qua_đời',\n",
       " 'arafat tiễn',\n",
       " 'arafat tiễn an_táng',\n",
       " 'are the',\n",
       " 'argentina brazil',\n",
       " 'argentina thắng',\n",
       " 'ariel sharon',\n",
       " 'arjen robben',\n",
       " 'armstrong mỹ',\n",
       " 'armstrong mỹ bưu_điện',\n",
       " 'arne friedrich',\n",
       " 'array new',\n",
       " 'array new array',\n",
       " 'arrigo sacchi',\n",
       " 'arsenal bolton',\n",
       " 'arsenal chelsea',\n",
       " 'arsenal chelsea mu',\n",
       " 'arsenal chiến_thắng',\n",
       " 'arsenal chấp',\n",
       " 'arsenal cầu_thủ',\n",
       " 'arsenal everton',\n",
       " 'arsenal henry',\n",
       " 'arsenal lehmann',\n",
       " 'arsenal liverpool',\n",
       " 'arsenal mu',\n",
       " 'arsenal mùa',\n",
       " 'arsenal panathinaikos',\n",
       " 'arsenal panathinaikos rosenborg',\n",
       " 'arsenal phút',\n",
       " 'arsenal thi_đấu',\n",
       " 'arsenal thua',\n",
       " 'arsenal thắng',\n",
       " 'arsenal tottenham',\n",
       " 'arsenal đấu',\n",
       " 'arsene wenger',\n",
       " 'as roma',\n",
       " 'as roma thủ_môn',\n",
       " 'ashley cole',\n",
       " 'ashley cole tiền_vệ',\n",
       " 'asian cup',\n",
       " 'aston villa',\n",
       " 'aston villa charlton',\n",
       " 'aston villa fulham',\n",
       " 'aston villa liverpool',\n",
       " 'aston villa man',\n",
       " 'aston villa tottenham',\n",
       " 'atalanta serie',\n",
       " 'athletic bilbao',\n",
       " 'atlantic groups',\n",
       " 'atlantic groups net',\n",
       " 'atletico madrid',\n",
       " 'atletico osasuna',\n",
       " 'atm giả',\n",
       " 'audio video',\n",
       " 'aung oo',\n",
       " 'australia cofidis',\n",
       " 'australia lotto',\n",
       " 'australia lotto domo',\n",
       " 'australia mở_rộng',\n",
       " 'australia new_zealand',\n",
       " 'australia việt_nam',\n",
       " 'aviv bảng',\n",
       " 'aviv bảng mu',\n",
       " 'axit béo',\n",
       " 'axit béo no',\n",
       " 'axit folic',\n",
       " 'ayrton senna',\n",
       " 'az alkmaar',\n",
       " 'azevedo bđn',\n",
       " 'azevedo bđn bưu_điện',\n",
       " 'ba_vì hà_tây',\n",
       " 'ba_đình hà',\n",
       " 'ba_đình hà nộiđt',\n",
       " 'ba_đình hà_nội',\n",
       " 'backup mypc',\n",
       " 'bae yong',\n",
       " 'bae yong joon',\n",
       " 'bae yong jun',\n",
       " 'baghdad km',\n",
       " 'bambang yudhoyono',\n",
       " 'ban an_toàn',\n",
       " 'ban an_toàn giao_thông',\n",
       " 'ban ban',\n",
       " 'ban biên',\n",
       " 'ban biên tậptiêu',\n",
       " 'ban biên_tập',\n",
       " 'ban biên_tập báo',\n",
       " 'ban chi',\n",
       " 'ban chuyên_án',\n",
       " 'ban chỉ_huy',\n",
       " 'ban chỉ_huy phòng_chống',\n",
       " 'ban chỉ_đạo',\n",
       " 'ban chỉ_đạo phòng_chống',\n",
       " 'ban chỉ_đạo quốc_gia',\n",
       " 'ban chỉ_đạo tuyển_sinh',\n",
       " 'ban chủ_nhiệm',\n",
       " 'ban co',\n",
       " 'ban co the',\n",
       " 'ban cong',\n",
       " 'ban cán_sự',\n",
       " 'ban cán_sự đảng',\n",
       " 'ban cán_sự đảng_bộ',\n",
       " 'ban công_tác',\n",
       " 'ban da',\n",
       " 'ban dang',\n",
       " 'ban dân_nguyện',\n",
       " 'ban dân_vận',\n",
       " 'ban giám_khảo',\n",
       " 'ban giám_đốc',\n",
       " 'ban giám_đốc công_an',\n",
       " 'ban giám_đốc công_ty',\n",
       " 'ban huấn_luyện',\n",
       " 'ban huấn_luyện cầu_thủ',\n",
       " 'ban huấn_luyện đội_tuyển',\n",
       " 'ban khong',\n",
       " 'ban kinh_tế',\n",
       " 'ban kinh_tế ngân_sách',\n",
       " 'ban kiểm',\n",
       " 'ban kiểm phiếu',\n",
       " 'ban kiểm_tra',\n",
       " 'ban kỷ_luật',\n",
       " 'ban kỷ_luật lđbđ',\n",
       " 'ban lãnh_đạo',\n",
       " 'ban lãnh_đạo clb',\n",
       " 'ban lãnh_đạo palestine',\n",
       " 'ban muon',\n",
       " 'ban nen',\n",
       " 'ban nghiên_cứu',\n",
       " 'ban nghiên_cứu thủ_tướng',\n",
       " 'ban nhạc',\n",
       " 'ban nhạc rock',\n",
       " 'ban nội_chính',\n",
       " 'ban nội_chính trung_ương',\n",
       " 'ban phai',\n",
       " 'ban quản_lý',\n",
       " 'ban quản_lý chợ',\n",
       " 'ban quản_lý dự_án',\n",
       " 'ban quản_lý khu',\n",
       " 'ban quản_lý lao_động',\n",
       " 'ban quản_trị',\n",
       " 'ban rock',\n",
       " 'ban soạn_thảo',\n",
       " 'ban thanh_tra',\n",
       " 'ban thư_ký',\n",
       " 'ban thường_trực',\n",
       " 'ban thường_vụ',\n",
       " 'ban thường_vụ tỉnh_uỷ',\n",
       " 'ban tuyên_giáo',\n",
       " 'ban tài_chính',\n",
       " 'ban tư_tưởng',\n",
       " 'ban tư_tưởng văn_hoá',\n",
       " 'ban tư_vấn',\n",
       " 'ban tổ_chức',\n",
       " 'ban tổ_chức btc',\n",
       " 'ban tổ_chức giải',\n",
       " 'ban tổ_chức lễ_hội',\n",
       " 'ban tổ_chức trao',\n",
       " 'ban văn',\n",
       " 'ban văn hoátiêu',\n",
       " 'ban văn_hoá',\n",
       " 'ban vận_động',\n",
       " 'ban điều_hành',\n",
       " 'ban đào_tạo',\n",
       " 'ban đỏ',\n",
       " 'ban đội_tuyển',\n",
       " 'ban_bố khẩn_cấp',\n",
       " 'ban_chấp_hành trung_ương',\n",
       " 'ban_chấp_hành trung_ương khoá',\n",
       " 'ban_chấp_hành trung_ương đảng',\n",
       " 'ban_chấp_hành đảng_bộ',\n",
       " 'ban_hành chính_sách',\n",
       " 'ban_hành chỉ_thị',\n",
       " 'ban_hành hướng_dẫn',\n",
       " 'ban_hành luật',\n",
       " 'ban_hành lệnh',\n",
       " 'ban_hành nghị_định',\n",
       " 'ban_hành quy_chế',\n",
       " 'ban_hành quy_định',\n",
       " 'ban_hành quyết_định',\n",
       " 'ban_hành thông_tư',\n",
       " 'ban_hành văn_bản',\n",
       " 'ban_hành văn_bản quy_phạm_pháp_luật',\n",
       " 'ban_ngành đoàn_thể',\n",
       " 'ban_đầu cơ_quan',\n",
       " 'ban_đầu usd',\n",
       " 'ban_đầu đối_tượng',\n",
       " 'bang california',\n",
       " 'bang california mỹ',\n",
       " 'bang delaware',\n",
       " 'bang florida',\n",
       " 'bang miền',\n",
       " 'bang mỹ',\n",
       " 'bang new',\n",
       " 'bang new york',\n",
       " 'bang ohio',\n",
       " 'bang texas',\n",
       " 'bangkok thái_lan',\n",
       " 'banh trái',\n",
       " 'bank of',\n",
       " 'bao cát',\n",
       " 'bao nhieu',\n",
       " 'bao quy',\n",
       " 'bao_gồm thuế',\n",
       " 'bao_gồm tiền',\n",
       " 'bao_gồm vat',\n",
       " 'baptista sevilla',\n",
       " 'bar honda',\n",
       " 'bar vũ_trường',\n",
       " 'barca real',\n",
       " 'barca thắng',\n",
       " 'barcelona chelsea',\n",
       " 'barcelona deportivo',\n",
       " 'barcelona mùa',\n",
       " 'barcelona real',\n",
       " 'barcelona real madrid',\n",
       " 'barcelona shakhtar',\n",
       " 'barcelona shakhtar celtic',\n",
       " 'barcelona thắng',\n",
       " 'barcelona thủ_môn',\n",
       " 'barcelona tây_ban_nha',\n",
       " 'barcelona đấu',\n",
       " 'barrichello ferrari',\n",
       " 'barrichello ferrari jenson',\n",
       " 'basel ii',\n",
       " 'basso italy',\n",
       " 'basso italy csc',\n",
       " 'bastian schweinsteiger',\n",
       " 'baumgartner minardi',\n",
       " 'bayer leverkusen',\n",
       " 'bayern ajax',\n",
       " 'bayern ajax tel',\n",
       " 'bayern munich',\n",
       " 'bbàn thắng',\n",
       " 'bbàn thắng thua',\n",
       " 'bch khoá',\n",
       " 'bch khoá ix',\n",
       " 'bch trung_ương',\n",
       " 'bch tư',\n",
       " 'bch đảng',\n",
       " 'bec tero',\n",
       " 'beckham real',\n",
       " 'ben affleck',\n",
       " 'benni mccarthy',\n",
       " 'bernabeu real',\n",
       " 'bernardo corradi',\n",
       " 'bernd schneider',\n",
       " 'bhl đội_tuyển',\n",
       " 'bia rượu',\n",
       " 'bia sài_gòn',\n",
       " 'big blue',\n",
       " 'bill clinton',\n",
       " 'bill gates',\n",
       " 'bin laden',\n",
       " 'binh_lính iraq',\n",
       " 'binh_lính mỹ',\n",
       " 'binh_sĩ iraq',\n",
       " 'binh_sĩ mỹ',\n",
       " 'birmingham city',\n",
       " 'birmingham palace',\n",
       " 'birmingham portsmouth',\n",
       " 'birmingham west',\n",
       " 'bixente lizarazu',\n",
       " 'biên ngang',\n",
       " 'biên trái',\n",
       " 'biên tậptiêu',\n",
       " 'biên tậptiêu đề',\n",
       " 'biên_bản vi_phạm',\n",
       " 'biên_bản xử_phạt',\n",
       " 'biên_giới campuchia',\n",
       " 'biên_giới trung_quốc',\n",
       " 'biên_giới việt_nam',\n",
       " 'biên_giới vn',\n",
       " 'biên_hoà đồng_nai',\n",
       " 'biên_phòng cửa_khẩu',\n",
       " 'biên_tập báo',\n",
       " 'biên_đạo múa',\n",
       " 'biếm_hoạ tiên_tri',\n",
       " 'biến giấc',\n",
       " 'biến giấc mơ',\n",
       " 'biến thành',\n",
       " 'biến thành thắng',\n",
       " 'biến_chứng bệnh',\n",
       " 'biến_chứng nguy_hiểm',\n",
       " 'biến_chứng viêm',\n",
       " 'biến_thể sâu',\n",
       " 'biến_đổi gene',\n",
       " 'biến_đổi khí_hậu',\n",
       " 'biến_động giá',\n",
       " 'biến_động thị_trường',\n",
       " 'biển biển',\n",
       " 'biển bà_rịa_vũng_tàu',\n",
       " 'biển bãi',\n",
       " 'biển bắc',\n",
       " 'biển chết',\n",
       " 'biển giả',\n",
       " 'biển khu_vực',\n",
       " 'biển khơi',\n",
       " 'biển kiểm_soát',\n",
       " 'biển nam',\n",
       " 'biển nha_trang',\n",
       " 'biển quảng_cáo',\n",
       " 'biển sâu',\n",
       " 'biển ta',\n",
       " 'biển tàu',\n",
       " 'biển tây',\n",
       " 'biển việt_nam',\n",
       " 'biển vũng_tàu',\n",
       " 'biển đẹp',\n",
       " 'biển đỏ',\n",
       " 'biển động',\n",
       " 'biển_thủ tiền',\n",
       " 'biểu mô',\n",
       " 'biểu_diễn ca_khúc',\n",
       " 'biểu_diễn ca_nhạc',\n",
       " 'biểu_diễn ca_sĩ',\n",
       " 'biểu_diễn chuyên_nghiệp',\n",
       " 'biểu_diễn chương_trình',\n",
       " 'biểu_diễn nghệ_thuật',\n",
       " 'biểu_diễn nhạc',\n",
       " 'biểu_diễn phục_vụ',\n",
       " 'biểu_diễn sân_khấu',\n",
       " 'biểu_diễn thời_trang',\n",
       " 'biểu_hiện bất_thường',\n",
       " 'biểu_hiện bệnh',\n",
       " 'biểu_hiện lâm_sàng',\n",
       " 'biểu_hiện sốt',\n",
       " 'biểu_hiện tiêu_cực',\n",
       " 'biểu_hiện triệu_chứng',\n",
       " 'biểu_hiện viêm',\n",
       " 'biểu_hiện đau',\n",
       " 'biểu_lộ tình_cảm',\n",
       " 'biểu_quyết thông_qua',\n",
       " 'biểu_tình chống',\n",
       " 'biểu_tình phản_đối',\n",
       " 'biểu_tình đòi',\n",
       " 'biện_pháp an_ninh',\n",
       " 'biện_pháp an_toàn',\n",
       " 'biện_pháp bảo_vệ',\n",
       " 'biện_pháp chấn_chỉnh',\n",
       " 'biện_pháp chế_tài',\n",
       " 'biện_pháp chống',\n",
       " 'biện_pháp cần_thiết',\n",
       " 'biện_pháp cứng_rắn',\n",
       " 'biện_pháp giúp',\n",
       " 'biện_pháp giải_quyết',\n",
       " 'biện_pháp hiệu_quả',\n",
       " 'biện_pháp hành_chính',\n",
       " 'biện_pháp hạn_chế',\n",
       " 'biện_pháp hữu_hiệu',\n",
       " 'biện_pháp khẩn_cấp',\n",
       " 'biện_pháp khắc_phục',\n",
       " 'biện_pháp kiểm_soát',\n",
       " 'biện_pháp kỹ_thuật',\n",
       " 'biện_pháp nghiệp_vụ',\n",
       " 'biện_pháp ngăn_chặn',\n",
       " 'biện_pháp nâng',\n",
       " 'biện_pháp phòng_chống',\n",
       " 'biện_pháp phòng_chống dịch',\n",
       " 'biện_pháp phòng_ngừa',\n",
       " 'biện_pháp phòng_tránh',\n",
       " 'biện_pháp quản_lý',\n",
       " 'biện_pháp thai',\n",
       " 'biện_pháp thúc_đẩy',\n",
       " 'biện_pháp trừng_phạt',\n",
       " 'biện_pháp tăng_cường',\n",
       " 'biện_pháp áp_dụng',\n",
       " 'biện_pháp điều_trị',\n",
       " 'biện_pháp đối_phó',\n",
       " 'biệt hoá',\n",
       " 'biệt_thự khu',\n",
       " 'bjelanovic lecce',\n",
       " 'blackburn norwich',\n",
       " 'blackburn portsmouth',\n",
       " 'blackburn rovers',\n",
       " 'blackburn southampton',\n",
       " 'block giây',\n",
       " 'blu ray',\n",
       " 'blu ray dvd',\n",
       " 'blue gene',\n",
       " 'bo ro',\n",
       " 'boa morte',\n",
       " 'boas salossa',\n",
       " 'bob woodward',\n",
       " 'bobby robson',\n",
       " 'boca juniors',\n",
       " 'bojinov lecce',\n",
       " 'bologna parma',\n",
       " 'bologna parma siena',\n",
       " 'bolton everton',\n",
       " 'bolton portsmouth',\n",
       " 'bolton wanderers',\n",
       " 'bom chết',\n",
       " 'bom hoà_bình',\n",
       " 'bom hoà_bình phó',\n",
       " 'bom hạt_nhân',\n",
       " 'bom liều',\n",
       " 'bom liều chết',\n",
       " 'bom madrid',\n",
       " 'bom nổ',\n",
       " 'bom phát_nổ',\n",
       " 'bom tự_sát',\n",
       " 'bong da',\n",
       " 'bong tróc',\n",
       " 'boris yeltsin',\n",
       " 'boro aston',\n",
       " 'boro aston villa',\n",
       " 'boro liverpool',\n",
       " 'borussia dortmund',\n",
       " 'boston mỹ',\n",
       " 'botulinum toxin',\n",
       " 'bql dự_án',\n",
       " 'br vt',\n",
       " 'brad pitt',\n",
       " 'brazil argentina',\n",
       " 'brazil thắng',\n",
       " 'brazil vô_địch',\n",
       " 'brazil đấu',\n",
       " 'break set',\n",
       " 'bremen valencia',\n",
       " 'bremen valencia anderlecht',\n",
       " 'brent london',\n",
       " 'brescia bologna',\n",
       " 'bridge chelsea',\n",
       " 'britney spears',\n",
       " 'brom sống_sót',\n",
       " 'brom sống_sót chelsea',\n",
       " 'bronckhorst tiền_vệ',\n",
       " 'bruni minardi',\n",
       " 'bs trần',\n",
       " 'bs đô',\n",
       " 'bs đô hô',\n",
       " 'btc giải',\n",
       " 'btc league',\n",
       " 'btc quyết_định',\n",
       " 'btc sân',\n",
       " 'buenos aires',\n",
       " 'buffet món',\n",
       " 'buffon hậu_vệ',\n",
       " 'bush bush',\n",
       " 'bush chính_sách',\n",
       " 'bush hôm_qua',\n",
       " 'bush kerry',\n",
       " 'bush mỹ',\n",
       " 'bush phát_biểu',\n",
       " 'bush quyết_tâm',\n",
       " 'bush quyết_tâm đẩy_mạnh',\n",
       " 'bush thủ_tướng',\n",
       " 'bush tuyên_bố',\n",
       " 'bush tái',\n",
       " 'bush tái đắc_cử',\n",
       " 'bush tổng_thống',\n",
       " 'button bar',\n",
       " 'buôn ma_tuý',\n",
       " 'buôn_bán gia_cầm',\n",
       " 'buôn_bán ma_tuý',\n",
       " 'buôn_bán phụ_nữ',\n",
       " 'buôn_bán phụ_nữ trẻ_em',\n",
       " 'buôn_bán vận_chuyển',\n",
       " 'buôn_lậu bị_cáo',\n",
       " 'buôn_lậu gian_lận',\n",
       " 'buôn_lậu gian_lận thương_mại',\n",
       " 'buôn_lậu hối_lộ',\n",
       " 'buôn_lậu ma_tuý',\n",
       " 'buôn_lậu trốn_thuế',\n",
       " 'buôn_lậu xăng_dầu',\n",
       " 'buôn_mê thuột',\n",
       " 'buông_lỏng quản_lý',\n",
       " 'buồn buồn',\n",
       " 'buồn chán',\n",
       " 'buồn gia_đình',\n",
       " 'buồn giận',\n",
       " 'buồn khổ',\n",
       " 'buồn lắm',\n",
       " 'buồn niềm',\n",
       " 'buồn vui',\n",
       " 'buồn_nôn nôn',\n",
       " 'buồng tử_cung',\n",
       " 'buộc bị_cáo',\n",
       " 'buộc chiến_thắng',\n",
       " 'buộc chấp_nhận',\n",
       " 'buộc chủ',\n",
       " 'buộc công_ty',\n",
       " 'buộc cầu_thủ',\n",
       " 'buộc hậu_vệ',\n",
       " 'buộc rời',\n",
       " 'buộc rời sân',\n",
       " 'buộc thắng',\n",
       " 'buộc thủ_môn',\n",
       " 'buộc thủ_thành',\n",
       " 'buộc tiền',\n",
       " 'buộc đối_thủ',\n",
       " 'bv chợ_rẫy',\n",
       " 'bv nhi',\n",
       " 'bv nhi_đồng',\n",
       " 'bv pháp',\n",
       " 'bv từ_dũ',\n",
       " 'bvtv sài_gòn',\n",
       " 'bvtv sài_gòn dofilm',\n",
       " 'byung hun',\n",
       " 'bà_con nông_dân',\n",
       " 'bà_con việt_kiều',\n",
       " 'bài_học kinh_nghiệm',\n",
       " 'bài_thuốc chữa',\n",
       " 'bàn_chải đánh',\n",
       " 'bàn_giao mặt_bằng',\n",
       " 'bàn_tay bàn_chân',\n",
       " 'bàng tử',\n",
       " 'bào sợi',\n",
       " 'bào_chữa bị_can',\n",
       " 'bào_chữa bị_cáo',\n",
       " 'bào_chữa luật_sư',\n",
       " 'bào_chữa saddam',\n",
       " 'bày_bán chợ',\n",
       " 'bày_tỏ bức_xúc',\n",
       " 'bày_tỏ hy_vọng',\n",
       " 'bày_tỏ hài_lòng',\n",
       " 'bày_tỏ lo_ngại',\n",
       " 'bày_tỏ mong_muốn',\n",
       " 'bày_tỏ niềm',\n",
       " 'bày_tỏ quan_điểm',\n",
       " 'bày_tỏ tin_tưởng',\n",
       " 'bày_tỏ tình_cảm',\n",
       " 'bày_tỏ ý_kiến',\n",
       " 'bày_tỏ ý_định',\n",
       " 'bày_tỏ ủng_hộ',\n",
       " 'bá chi',\n",
       " 'bá quốc_gia',\n",
       " 'bá quốc_gia tp',\n",
       " 'bác_bỏ cáo_buộc',\n",
       " 'bác_bỏ thông_tin',\n",
       " 'bác_bỏ đề_nghị',\n",
       " 'bác_sĩ arafat',\n",
       " 'bác_sĩ arafat giải_phẫu',\n",
       " 'bác_sĩ bác_sĩ',\n",
       " 'bác_sĩ bảo',\n",
       " 'bác_sĩ bệnh',\n",
       " 'bác_sĩ bệnh_nhân',\n",
       " 'bác_sĩ bệnh_viện',\n",
       " 'bác_sĩ chuyên_khoa',\n",
       " 'bác_sĩ chẩn_đoán',\n",
       " 'bác_sĩ chỉ_định',\n",
       " 'bác_sĩ cắt',\n",
       " 'bác_sĩ giúp',\n",
       " 'bác_sĩ khoa',\n",
       " 'bác_sĩ khuyên',\n",
       " 'bác_sĩ khuyến_cáo',\n",
       " 'bác_sĩ khám',\n",
       " 'bác_sĩ kê',\n",
       " 'bác_sĩ kê đơn',\n",
       " 'bác_sĩ kết_luận',\n",
       " 'bác_sĩ mổ',\n",
       " 'bác_sĩ nguyên_nhân',\n",
       " 'bác_sĩ nguyễn_thành',\n",
       " 'bác_sĩ nguyễn_thị',\n",
       " 'bác_sĩ nguyễn_văn',\n",
       " 'bác_sĩ phan',\n",
       " 'bác_sĩ pháp',\n",
       " 'bác_sĩ phát_hiện',\n",
       " 'bác_sĩ phạm',\n",
       " 'bác_sĩ phẫu_thuật',\n",
       " 'bác_sĩ quyết_định',\n",
       " 'bác_sĩ theo_dõi',\n",
       " 'bác_sĩ thuốc',\n",
       " 'bác_sĩ thú_y',\n",
       " 'bác_sĩ tiến_hành',\n",
       " 'bác_sĩ trung_tâm',\n",
       " 'bác_sĩ trương',\n",
       " 'bác_sĩ trương thìn',\n",
       " 'bác_sĩ trần',\n",
       " 'bác_sĩ trần thị',\n",
       " 'bác_sĩ ts',\n",
       " 'bác_sĩ ts lý',\n",
       " 'bác_sĩ tâm_lý',\n",
       " 'bác_sĩ tâm_thần',\n",
       " 'bác_sĩ tư_vấn',\n",
       " 'bác_sĩ y_tá',\n",
       " 'bác_sĩ điều_trị',\n",
       " 'bách_khoa hà_nội',\n",
       " 'bách_khoa tp',\n",
       " 'bách_khoa tp hcm',\n",
       " 'bách_khoa tphcm',\n",
       " 'bám sát',\n",
       " 'bám thành',\n",
       " 'bám đuổi',\n",
       " 'bán_buôn bán_lẻ',\n",
       " 'bán_công marketing',\n",
       " 'bán_công tp',\n",
       " 'bán_công tphcm',\n",
       " 'bán_công tôn',\n",
       " 'bán_công tôn đức',\n",
       " 'bán_kính km',\n",
       " 'bán_kết champions',\n",
       " 'bán_kết champions league',\n",
       " 'bán_kết chung_kết',\n",
       " 'bán_kết cup',\n",
       " 'bán_kết cup fa',\n",
       " 'bán_kết cúp',\n",
       " 'bán_kết cúp fa',\n",
       " 'bán_kết euro',\n",
       " 'bán_kết giải',\n",
       " 'bán_kết hlv',\n",
       " 'bán_kết lượt_về',\n",
       " 'bán_kết lượt_đi',\n",
       " 'bán_kết sea_games',\n",
       " 'bán_kết tay_vợt',\n",
       " 'bán_kết thắng',\n",
       " 'bán_kết tiger',\n",
       " 'bán_kết tiger cup',\n",
       " 'bán_kết đấu',\n",
       " 'bán_kết đối_thủ',\n",
       " 'bán_lẻ giá',\n",
       " 'bán_phá_giá doc',\n",
       " 'bán_phá_giá doc phán_quyết',\n",
       " 'bán_phá_giá mỹ',\n",
       " 'bán_đảo triều_tiên',\n",
       " 'bán_đấu_giá tài_sản',\n",
       " 'bán_độ cầu_thủ',\n",
       " 'bán_độ sea_games',\n",
       " 'bán_độ vn',\n",
       " 'bánh bánh',\n",
       " 'bánh bột',\n",
       " 'bánh heroin',\n",
       " 'bánh kem',\n",
       " 'bánh mứt',\n",
       " 'bánh mỳ',\n",
       " 'bánh trớn',\n",
       " 'bánh xích',\n",
       " 'báo báo',\n",
       " 'báo cháy',\n",
       " 'báo công_an',\n",
       " 'báo cảnh_sát',\n",
       " 'báo gia_đình',\n",
       " 'báo in',\n",
       " 'báo kinh_tế',\n",
       " 'báo lao_động',\n",
       " 'báo lao_động phản_ánh',\n",
       " 'báo lao_động thông_tin',\n",
       " 'báo lao_động tổ_chức',\n",
       " 'báo lỗi',\n",
       " 'báo mỹ',\n",
       " 'báo nhân_dân',\n",
       " 'báo nlđ',\n",
       " 'báo nêu',\n",
       " 'báo pháp_luật',\n",
       " 'báo pháp_luật tp',\n",
       " 'báo sài_gòn',\n",
       " 'báo thanh_niên',\n",
       " 'báo thanh_niên chương_trình',\n",
       " 'báo thanh_niên tổ_chức',\n",
       " 'báo thanh_niên đăng',\n",
       " 'báo the',\n",
       " 'báo thông_tin',\n",
       " 'báo thể_thao',\n",
       " 'báo tiền_phong',\n",
       " 'báo tuổi_trẻ',\n",
       " 'báo tạp_chí',\n",
       " 'báo viết',\n",
       " 'báo đài',\n",
       " 'báo đăng',\n",
       " 'báo địa_phương',\n",
       " 'báo_chí giới',\n",
       " 'báo_chí mỹ',\n",
       " 'báo_chí nêu',\n",
       " 'báo_chí nước_ngoài',\n",
       " 'báo_chí phản_ánh',\n",
       " 'báo_chí thông_tin',\n",
       " 'báo_chí thế_giới',\n",
       " 'báo_chí đăng',\n",
       " 'báo_chí địa_phương',\n",
       " 'báo_cáo ban',\n",
       " 'báo_cáo ban công_tác',\n",
       " 'báo_cáo bộ_trưởng',\n",
       " 'báo_cáo chính_phủ',\n",
       " 'báo_cáo chính_trị',\n",
       " 'báo_cáo chính_trị đại_hội',\n",
       " 'báo_cáo công_bố',\n",
       " 'báo_cáo công_tác',\n",
       " 'báo_cáo cơ_quan',\n",
       " 'báo_cáo cục',\n",
       " 'báo_cáo giám_sát',\n",
       " 'báo_cáo giải_trình',\n",
       " 'báo_cáo hội_đồng',\n",
       " 'báo_cáo khoa_học',\n",
       " 'báo_cáo kiểm_điểm',\n",
       " 'báo_cáo kế_hoạch',\n",
       " 'báo_cáo kết_quả',\n",
       " 'báo_cáo lãnh_đạo',\n",
       " 'báo_cáo nêu',\n",
       " 'báo_cáo phát_triển',\n",
       " 'báo_cáo sở',\n",
       " 'báo_cáo thủ_tướng',\n",
       " 'báo_cáo thủ_tướng chính_phủ',\n",
       " 'báo_cáo tài_chính',\n",
       " 'báo_cáo tình_hình',\n",
       " 'báo_cáo tổ_chức',\n",
       " 'báo_cáo ubnd',\n",
       " 'báo_cáo ubnd tp',\n",
       " 'báo_cáo uỷ_ban',\n",
       " 'báo_cáo đại_hội',\n",
       " 'báo_cáo đầy_đủ',\n",
       " 'báo_động đỏ',\n",
       " 'bát canh',\n",
       " 'bát cơm',\n",
       " 'bát mì',\n",
       " 'bát tràng',\n",
       " 'bãi biển',\n",
       " 'bãi cháy',\n",
       " 'bãi cát',\n",
       " 'bãi cỏ',\n",
       " 'bãi rác',\n",
       " 'bãi đá',\n",
       " 'bãi đậu',\n",
       " 'bãi đỗ',\n",
       " 'bãi_bỏ hạn_ngạch',\n",
       " 'bão bão',\n",
       " 'bão di_chuyển',\n",
       " 'bão giá',\n",
       " 'bão katrina',\n",
       " 'bão lũ',\n",
       " 'bão đổ_bộ',\n",
       " 'bè cá',\n",
       " 'bén duyên',\n",
       " 'béo ngậy',\n",
       " 'béo no',\n",
       " 'béo phì',\n",
       " 'bê nh',\n",
       " 'bìa cứng',\n",
       " 'bìa trái',\n",
       " 'bìa tạp_chí',\n",
       " 'bìa đĩa',\n",
       " 'bình bình',\n",
       " 'bình chứa',\n",
       " 'bình chừng',\n",
       " 'bình chừng phút',\n",
       " 'bình dương',\n",
       " 'bình dương bình',\n",
       " 'bình gas',\n",
       " 'bình giám_đốc',\n",
       " 'bình gốm',\n",
       " 'bình hoa',\n",
       " 'bình hưng',\n",
       " 'bình hưng hoà',\n",
       " 'bình kg',\n",
       " 'bình lợi',\n",
       " 'bình nhưỡng',\n",
       " 'bình phó',\n",
       " 'bình phú',\n",
       " 'bình quới',\n",
       " 'bình rượu',\n",
       " 'bình trị',\n",
       " 'bình trị bình_tân',\n",
       " 'bình trọng',\n",
       " 'bình tây',\n",
       " 'bình xăng',\n",
       " 'bình điền',\n",
       " 'bình điền long_an',\n",
       " 'bình định',\n",
       " 'bình định bình',\n",
       " 'bình định gđt',\n",
       " 'bình_chánh thủ_đức',\n",
       " 'bình_chánh tp',\n",
       " 'bình_chánh tp hcm',\n",
       " 'bình_chánh tphcm',\n",
       " 'bình_chọn giải',\n",
       " 'bình_dân tp',\n",
       " 'bình_dương bd',\n",
       " 'bình_dương hagl',\n",
       " 'bình_dương thắng',\n",
       " 'bình_dương đà_nẵng',\n",
       " 'bình_luận thông_tin',\n",
       " 'bình_phục chấn_thương',\n",
       " 'bình_quân usd',\n",
       " 'bình_thường bao',\n",
       " 'bình_thường bác_sĩ',\n",
       " 'bình_thường cuộc_sống',\n",
       " 'bình_thường phụ_nữ',\n",
       " 'bình_thạnh tp',\n",
       " 'bình_thạnh tp hcm',\n",
       " 'bình_thạnh tphcm',\n",
       " 'bình_tân tp',\n",
       " 'bình_tân tp hcm',\n",
       " 'bình_tĩnh đừng',\n",
       " 'bình_đẳng giới',\n",
       " 'bình_định bđ',\n",
       " 'bình_ổn giá',\n",
       " 'bình_ổn thị_trường',\n",
       " 'bí_quyết giúp',\n",
       " 'bí_quyết thành_công',\n",
       " 'bí_thư chi_bộ',\n",
       " 'bí_thư huyện_uỷ',\n",
       " 'bí_thư thành_uỷ',\n",
       " 'bí_thư thành_uỷ nguyễn_minh_triết',\n",
       " 'bí_thư thành_uỷ tp',\n",
       " 'bí_thư thường_trực',\n",
       " 'bí_thư trung_ương',\n",
       " 'bí_thư trung_ương đảng',\n",
       " 'bí_thư tỉnh_uỷ',\n",
       " 'bí_thư tỉnh_uỷ chủ_tịch',\n",
       " 'bí_thư đảng_uỷ',\n",
       " 'bích hạnh',\n",
       " 'bích thuỷ',\n",
       " 'bính tuất',\n",
       " 'bò thịt',\n",
       " 'bò điên',\n",
       " 'bó bột',\n",
       " 'bó hoa',\n",
       " 'bó sát',\n",
       " 'bó xôi',\n",
       " 'bó_tay thủ_môn',\n",
       " 'bóc gỡ',\n",
       " 'bóc gỡ đường_dây',\n",
       " 'bóc tách',\n",
       " 'bóc vỏ',\n",
       " 'bón phân',\n",
       " 'bóng_chuyền bãi',\n",
       " 'bóng_chuyền bãi biển',\n",
       " 'bóng_chuyền nữ',\n",
       " 'bóng_chuyền tp',\n",
       " 'bóng_chuyền tp hcm',\n",
       " 'bóng_chuyền vn',\n",
       " 'bóng_đá argentina',\n",
       " 'bóng_đá brazil',\n",
       " 'bóng_đá bồ_đào_nha',\n",
       " 'bóng_đá chuyên_nghiệp',\n",
       " 'bóng_đá cầu_thủ',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect_ngram.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram-char level - we choose max number of words equal to 30000 except all words (100k+ words)\n",
    "tfidf_vect_ngram_char = TfidfVectorizer(analyzer='char', max_features=30000, ngram_range=(2, 3))\n",
    "tfidf_vect_ngram_char.fit(X_data)\n",
    "X_data_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_data)\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf_ngram_char =  tfidf_vect_ngram_char.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform by SVD to decrease number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd.fit(X_data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_tfidf_svd = svd.transform(X_data_tfidf)\n",
    "X_test_tfidf_svd = svd.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_ngram = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd_ngram.fit(X_data_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_tfidf_ngram_svd = svd_ngram.transform(X_data_tfidf_ngram)\n",
    "X_test_tfidf_ngram_svd = svd_ngram.transform(X_test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram Char Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TruncatedSVD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-d7d428161836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvd_ngram_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msvd_ngram_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data_tfidf_ngram_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TruncatedSVD' is not defined"
     ]
    }
   ],
   "source": [
    "svd_ngram_char = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd_ngram_char.fit(X_data_tfidf_ngram_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_tfidf_ngram_char_svd = svd_ngram_char.transform(X_data_tfidf_ngram_char)\n",
    "X_test_tfidf_ngram_char_svd = svd_ngram_char.transform(X_test_tfidf_ngram_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Word Embeddings</h3>\n",
    "\n",
    "We will convert each word in document to a embedding vector. We will use pretrained model for Vietnamese. The model can be downloaded from https://github.com/Kyubyong/wordvectors\n",
    "\n",
    "Assume that, one document have\n",
    "word, each word is represented by 300 dimensional vector, then the document vector be 2-dimensional matrix with size . From that, we can use DNN, RNN, CNN model for this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "word2vec_model_path = os.path.join(dir_path, \"Data/vi/vi.vec\")\n",
    "\n",
    "w2v = KeyedVectors.load_word2vec_format(word2vec_model_path)\n",
    "vocab = w2v.wv.vocab\n",
    "wv = w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec_data(X):\n",
    "    word2vec_data = []\n",
    "    for x in X:\n",
    "        sentence = []\n",
    "        for word in x.split(\" \"):\n",
    "            if word in vocab:\n",
    "#                 print(word)\n",
    "                sentence.append(wv[word])\n",
    "\n",
    "        word2vec_data.append(sentence)\n",
    "#         break\n",
    "    return word2vec_data\n",
    "\n",
    "X_data_w2v = get_word2vec_data(X_data)\n",
    "X_test_w2v = get_word2vec_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert y to categorical</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_data_n = encoder.fit_transform(y_data)\n",
    "y_test_n = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model</h2>\n",
    "We will implement these models:\n",
    "\n",
    "1. Naive Bayes Classifier\n",
    "2. Linear Classifier\n",
    "3. Support Vector Machine\n",
    "4. Bagging Models\n",
    "5. Boosting Models\n",
    "6. Shallow Neural Networks\n",
    "7. Deep Neural Networks\n",
    "- Convolutional Neural Network (CNN)\n",
    "- Long Short Term Modelr (LSTM)\n",
    "- Gated Recurrent Unit (GRU)\n",
    "- Bidirectional RNN\n",
    "- Recurrent Convolutional Neural Network (RCNN)\n",
    "- Other Variants of Deep Neural Networks\n",
    "8. Doc2Vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.1, random_state=42)\n",
    "    \n",
    "    if is_neuralnet:\n",
    "        classifier.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, batch_size=512)\n",
    "        \n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        val_predictions = val_predictions.argmax(axis=-1)\n",
    "        test_predictions = test_predictions.argmax(axis=-1)\n",
    "    else:\n",
    "        classifier.fit(X_train, y_train)\n",
    "    \n",
    "        train_predictions = classifier.predict(X_train)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        \n",
    "    print(\"Validation accuracy: \", metrics.accuracy_score(val_predictions, y_val))\n",
    "    print(\"Test accuracy: \", metrics.accuracy_score(test_predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(naive_bayes.MultinomialNB(), X_data_tfidf, y_data, X_test_tfidf, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(naive_bayes.MultinomialNB(), X_data_tfidf_ngram_svd, y_data, X_test_tfidf_ngram_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(naive_bayes.MultinomialNB(), X_data_tfidf_ngram_char_svd, y_data, X_test_tfidf_ngram_char_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Other type Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(naive_bayes.BernoulliNB(), X_data_tfidf, y_data, X_test_tfidf, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(naive_bayes.BernoulliNB(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(linear_model.LogisticRegression(), X_data_tfidf, y_data, X_test_tfidf, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(linear_model.LogisticRegression(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(svm.SVC(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bagging Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(ensemble.RandomForestClassifier(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Boosting Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(xgboost.XGBClassifier(), X_data_tfidf_svd, y_data, X_test_tfidf_svd, y_test, is_neuralnet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>\n",
    "Deep Neural Network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "def create_dnn_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    layer = Dense(1024, activation='relu')(input_layer)\n",
    "    layer = Dense(1024, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    \n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = create_dnn_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recurrent Neural Network</h3>\n",
    "<h4>LSTM</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    \n",
    "    layer = Reshape((10, 30))(input_layer)\n",
    "    layer = LSTM(128, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(128, activation='relu')(layer)\n",
    "    \n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    \n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    \n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_lstm_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "Bidirectional RNN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brnn_model():\n",
    "    input_layer = Input(shape=(300,))\n",
    "    \n",
    "    layer = Reshape((10, 30))(input_layer)\n",
    "    layer = Bidirectional(GRU(128, activation='relu'))(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(512, activation='relu')(layer)\n",
    "    layer = Dense(128, activation='relu')(layer)\n",
    "    \n",
    "    output_layer = Dense(10, activation='softmax')(layer)\n",
    "    \n",
    "    classifier = models.Model(input_layer, output_layer)\n",
    "    \n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_brnn_model()\n",
    "train_model(classifier=classifier, X_data=X_data_tfidf_svd, y_data=y_data_n, X_test=X_test_tfidf_svd, y_test=y_test_n, is_neuralnet=True, n_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "89e28ffb6dbd571b5c23599cae50f6b9706f99db5e1c832a49046d1a757b023e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
